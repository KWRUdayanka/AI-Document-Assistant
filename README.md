# ğŸ§  AI Document Assistant

This script handles the ingestion of `.pdf`, `.docx`, and `.txt` documents into a Qdrant vector database using LlamaIndex, OpenAI embeddings, and QdrantClient.

A **Retrieval-Augmented Generation (RAG)** chatbot built using:

- ğŸ§ª FastAPI for serving queries
- ğŸ“¦ Qdrant for semantic vector storage
- ğŸ¤– OpenAI for embeddings and GPT-powered answers
- ğŸ§  LlamaIndex for context-based answer synthesis
- ğŸ¨ Custom logging for clear CLI feedback

---

![screenshot](docs/Screenshot 2025-08-01 230800.png)
![screenshot](docs/Screenshot 2025-08-01 230854.png)

---

## ğŸ“‚ Folder Structure

```
project-root/
â”‚
â”œâ”€â”€ data/                     # Place your documents here (PDF, DOCX, TXT)
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ingest.py             # Main ingestion script
â”‚   â””â”€â”€ query.py              # Chat interface / query engine
â”‚   â””â”€â”€ utils.py              # Helper functions
â”‚   â””â”€â”€ custom_logging.py     # Logging setup (if used)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .env                      # Environment variables
â”œâ”€â”€ README.md
â””â”€â”€ run_chatbot.py            # Entry point for demo
```
## ğŸ§¬ Environment Setup
- Clone this repository
```bash
Copy
Edit
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

---
## âš™ï¸ Environment Variables (`.env`)

```env
QDRANT_COLLECTION=dfn_collection_name
OPENAI_API_KEY=your_openai_key
```

---

## ğŸš€ Setup & Run

1. **Install dependencies**

```bash
pip install -r requirements.txt
```

2. **Prepare your `.env` and `data/` folder.**

3. **Run the ingestion script**

```bash
python src/ingest.py
```

4. **Run the run_chatbot script**

```bash
python run_chatbot.py
```

---

## ğŸ§° **Technologies Used**

| Component  | Description                     |
|------------|---------------------------------|
| FastAPI    | REST API framework              |
| Qdrant    | Vector similarity search engine  |
| OpenAI    | Embedding and LLM provider       |
| LlamaIndex | RAG engine and response synthesizer |
| Uvicorn   | ASGI server                     |
| Dotenv    | Environment config              |
| Colorlog  | Colorful terminal logging       |

---

## ğŸ’¬ Query the API

- You can now send POST requests to the API to ask questions.
## Example using curl:
```
curl --location 'http://127.0.0.1:8000/query' \
--header 'Content-Type: application/json' \
--data '{
    "text": "How do I use Qdrant?"
}'
```
## Or use Postman:
- Method: POST
- URL: http://127.0.0.1:8000/query
- Body: raw â†’ JSON
```
{
  "text": "How do I use Qdrant?"
}
```

---

## ğŸš€ Features

- âœ… Supports `.pdf`, `.docx`, and `.txt` files
- âœ… Chunks documents into manageable token sizes
- âœ… Embeds each chunk using OpenAI
- âœ… Stores chunks with metadata in Qdrant
- âœ… Auto-creates collection if it doesnâ€™t exist
- ğŸ” Semantic document search (OpenAI embeddings + Qdrant)
- ğŸ§  Contextual LLM-based answering with LlamaIndex
- ğŸš€ FastAPI REST API endpoint: `POST /query`
- âœ… Colorful logs for easy debugging and clarity

---

## ğŸ“¦ Qdrant Setup (Optional)

Ensure Qdrant is running on `localhost`. If you donâ€™t have it:

```bash
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
```

---

## .env

- QDRANT_COLLECTION=your_collection_name
- OPENAI_API_KEY=your_openai_api_key
- JWT_SECRET_KEY=your_secret_key


---

## ğŸ§ª Output

- Logs progress, errors, and chunk details
- Embedding vectors and metadata are stored in Qdrant collection defined in `.env`

---

## ğŸ› ï¸ Tech Stack

- Python 3.10+
- FastAPI
- LlamaIndex
- Qdrant
- OpenAI (Embeddings + GPT)
- PyMuPDF, python-docx
- colorlog

---

## ğŸ“¥ Output & Logs

- Progress and errors are printed with color-coded logs.
- Embedded documents are stored in your specified Qdrant collection.
---

## ğŸ“„ Requirements

You can generate the dependencies list with:

```bash
pip freeze > requirements.txt
```

Sample minimum requirements:

```txt
openai
llama-index
qdrant-client
python-dotenv
colorlog
PyMuPDF
python-docx
tqdm
fastapi
uvicorn
```
---

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourname/ai-document-assistant.git
cd ai-document-assistant
pip install -r requirements.txt
cp .env.example .env  # Add your OpenAI key here
```

---

## ğŸ“Œ License

- MIT or customize as needed.

---

## ğŸ—ƒï¸ Query Flow

- User sends a query via /query.
- Embedding generated using OpenAIEmbedding.
- Vector search in Qdrant.
- Top K documents retrieved.
- Documents passed to LlamaIndex synthesizer.
- Response returned to user.

---

## ğŸ™‹â€â™‚ï¸ Author

- Created by [Rashan Udayanka] â€” AI + RAG developer.

---

## ğŸ“Œ To-Do
- Add authentication with JWT
- Dockerize the app
- Add unit tests
- Frontend for chat